# DataFlux Func 维护手册

本文档主要面向运维，提供有关DataFlux Func 部署、故障排除等相关介绍

## 目录

<!-- MarkdownTOC -->

- [1. 快速部署](#1-%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2)
- [2. 日常维护](#2-%E6%97%A5%E5%B8%B8%E7%BB%B4%E6%8A%A4)
    - [2.1 更新部署](#21-%E6%9B%B4%E6%96%B0%E9%83%A8%E7%BD%B2)
    - [2.2 重启系统](#22-%E9%87%8D%E5%90%AF%E7%B3%BB%E7%BB%9F)
    - [2.3 查看Docker Stack 配置](#23-%E6%9F%A5%E7%9C%8Bdocker-stack-%E9%85%8D%E7%BD%AE)
    - [2.3 查看DataFlux Func 配置](#23-%E6%9F%A5%E7%9C%8Bdataflux-func-%E9%85%8D%E7%BD%AE)
    - [2.4 查看资源文件目录](#24-%E6%9F%A5%E7%9C%8B%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95)
    - [2.5 查看日志](#25-%E6%9F%A5%E7%9C%8B%E6%97%A5%E5%BF%97)
    - [2.6 数据库自动备份](#26-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD)
    - [2.7 完全卸载](#27-%E5%AE%8C%E5%85%A8%E5%8D%B8%E8%BD%BD)
    - [2.8 参数调整](#28-%E5%8F%82%E6%95%B0%E8%B0%83%E6%95%B4)
    - [2.9 迁移数据库](#29-%E8%BF%81%E7%A7%BB%E6%95%B0%E6%8D%AE%E5%BA%93)
    - [2.10 高可用部署](#210-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%83%A8%E7%BD%B2)
- [3. 故障排查](#3-%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5)
    - [3.1 安装部署时脚本中断](#31-%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E6%97%B6%E8%84%9A%E6%9C%AC%E4%B8%AD%E6%96%AD)
    - [3.2 安装部署完成后无法启动](#32-%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E5%AE%8C%E6%88%90%E5%90%8E%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8)
    - [3.3 安装部署完成后启动成功但无法访问](#33-%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E5%AE%8C%E6%88%90%E5%90%8E%E5%90%AF%E5%8A%A8%E6%88%90%E5%8A%9F%E4%BD%86%E6%97%A0%E6%B3%95%E8%AE%BF%E9%97%AE)
    - [3.4 函数执行返回超时](#34-%E5%87%BD%E6%95%B0%E6%89%A7%E8%A1%8C%E8%BF%94%E5%9B%9E%E8%B6%85%E6%97%B6)
        - [3.4.1 函数执行耗时过长导致工作进程被Kill](#341-%E5%87%BD%E6%95%B0%E6%89%A7%E8%A1%8C%E8%80%97%E6%97%B6%E8%BF%87%E9%95%BF%E5%AF%BC%E8%87%B4%E5%B7%A5%E4%BD%9C%E8%BF%9B%E7%A8%8B%E8%A2%ABkill)
        - [3.4.2 函数执行耗时过长导致API接口提前返回](#342-%E5%87%BD%E6%95%B0%E6%89%A7%E8%A1%8C%E8%80%97%E6%97%B6%E8%BF%87%E9%95%BF%E5%AF%BC%E8%87%B4api%E6%8E%A5%E5%8F%A3%E6%8F%90%E5%89%8D%E8%BF%94%E5%9B%9E)
    - [3.5 函数执行无响应](#35-%E5%87%BD%E6%95%B0%E6%89%A7%E8%A1%8C%E6%97%A0%E5%93%8D%E5%BA%94)
        - [3.5.1 测试函数有响应](#351-%E6%B5%8B%E8%AF%95%E5%87%BD%E6%95%B0%E6%9C%89%E5%93%8D%E5%BA%94)
        - [3.5.2 测试函数无响应](#352-%E6%B5%8B%E8%AF%95%E5%87%BD%E6%95%B0%E6%97%A0%E5%93%8D%E5%BA%94)

<!-- /MarkdownTOC -->

## 1. 快速部署

有关DataFlux Func 快速部署（即使用全自动脚本部署）的内容，见`README.md`

此处不再重复说明

## 2. 日常维护

默认情况下，安装目录为`/usr/local/dataflux-func`

### 2.1 更新部署

*注意：如果最初安装时指定了不同安装目录，更新时也需要指定完全相同的目录才行*

需要更新部署时，请按照以下步骤进行：

1. 使用`docker stack rm dataflux-func`命令，移除正在运行的服务（此步骤可能需要一定时间）
2. 使用`docker ps`确认所有容器都已经退出
3. 重新部署即可（脚本不会删除原先的数据）

### 2.2 重启系统

需要重新启动时，请按照以下步骤进行：

1. 使用`docker stack rm dataflux-func`命令，移除正在运行的服务（此步骤可能需要一定时间）
2. 使用`docker ps`确认所有容器都已经退出
3. 使用`docker stack deploy dataflux-func -c {安装目录}/docker-stack.yaml`重启所有服务

### 2.3 查看Docker Stack 配置

默认情况下，Docker Stack 配置文件保存位置如下：

|   环境   |            文件位置            |
|----------|--------------------------------|
| 宿主机内 | `{安装目录}/docker-stack.yaml` |

### 2.3 查看DataFlux Func 配置

默认情况下，配置文件保存位置如下：

|   环境   |              文件位置              |
|----------|------------------------------------|
| 容器内   | `/data/user-config.yaml`           |
| 宿主机内 | `{安装目录}/data/user-config.yaml` |

### 2.4 查看资源文件目录

默认情况下，资源文件目录保存位置如下：

|   环境   |           目录位置           |
|----------|------------------------------|
| 容器内   | `/data/resources/`           |
| 宿主机内 | `{安装目录}/data/resources/` |

资源文件目录可能包含以下内容：

|                  宿主机目录位置                   |                       说明                       |
|---------------------------------------------------|--------------------------------------------------|
| `{安装目录}/data/resources/extra-python-packages` | 通过UI界面「PIP工具」安装的额外Python 包存放位置 |
| `{安装目录}/data/resources/uploads`               | 通过接口上传文件的临时存放目录（会自动回卷清理） |

开发者/用户也可以自行将所需的其他资源文件存放在`{安装目录}/data/resources`下，
以便在脚本中读取使用。

*以上目录程序会自动创建*

### 2.5 查看日志

默认情况下，日志文件保存位置如下：

|   环境   |                 文件位置                 |
|----------|------------------------------------------|
| 容器内   | `/data/logs/dataflux-func.log`           |
| 宿主机内 | `{安装目录}/data/logs/dataflux-func.log` |

默认情况下，日志文件会根据logrotate配置自动回卷并压缩保存
（logrotate配置文件位置为`/etc/logrotate.d/dataflux-func`）

### 2.6 数据库自动备份

DataFlux Func 会定期自动备份完整的数据库为sql文件

默认情况下，数据库备份文件保存位置如下：

|   环境   |                               文件位置                              |
|----------|---------------------------------------------------------------------|
| 容器内   | `/data/sqldump/dataflux-func-sqldump-YYYYMMDD-hhmmss.sql`           |
| 宿主机内 | `{安装目录}/data/sqldump/dataflux-func-sqldump-YYYYMMDD-hhmmss.sql` |

*提示：旧版本的备份文件命名可能为`dataflux-sqldump-YYYYMMDD-hhmmss.sql`*

默认情况下，数据库备份文件每小时整点备份一次，最多保留7天（共168份）

### 2.7 完全卸载

某些情况无法直接升级的时候，可以先完全卸载后重新部署

需要完全卸载时，请按照以下步骤进行：

1. 视情况需要，使用脚本集导出功能导出脚本数据
2. 使用`docker stack rm dataflux-func`命令，移除正在运行的旧版本（此步骤可能需要一定时间）
3. 使用`rm -rf {安装目录}`命令，移除所有相关数据

### 2.8 参数调整

默认的参数主要应对最常见的情况，一些比较特殊的场景可以调整部分参数来优化系统：

|              参数             |  默认值   |                                                   说明                                                  |
|-------------------------------|-----------|---------------------------------------------------------------------------------------------------------|
| `LOG_LEVEL`                   | `WARNING` | 日志等级。<br>可以改为`ERROR`减少日志输出量。<br>或直接改为`NONE`禁用日志                               |
| `_WORKER_CONCURRENCY`         | `5`       | 工作单元进程数量。<br>如存在大量慢IO任务（耗时大于1秒），可改为`20`提高并发量，但不要过大，防止内存耗尽 |
| `_WORKER_PREFETCH_MULTIPLIER` | `10`      | 工作单元任务预获取数量。<br>如存在大量慢速任务（耗时大于1秒），建议改为`1`                              |

### 2.9 迁移数据库

如系统部署后通过了最初的单机验证阶段，
需要将数据库切换至外部数据库（如：阿里云RDS、Redis），
可根据以下步骤进行操作：

*注意：当使用外部数据库时，应确保MySQL版本为5.7，Redis版本为4.0以上*

*注意：DataFlux Func 不支持集群部署的Redis*

1. 在外部数据库实例中创建数据库，且确保如下两项配置：
    - `character-set-server=utf8mb4`
    - `collation-server=utf8mb4_unicode_ci`
2. 根据上文「数据库自动备份」找到最近的MySQL数据库备份文件，将其导入外部数据库
3. 根据上文「查看DataFlux Func 配置」找到配置文件，并根据实际情况修改以下字段内容：
    - `MYSQL_HOST`
    - `MYSQL_PORT`
    - `MYSQL_USER`
    - `MYSQL_PASSWORD`
    - `MYSQL_DATABASE`
    - `REDIS_HOST`
    - `REDIS_PORT`
    - `REDIS_DATABASE`
    - `REDIS_PASSWORD`
4. 根据上文「查看Docker Stack 配置」找到Docker Stack 文件，删除其中的MySQL 和Redis 相关部分（注释掉即可）
5. 根据上文「重启系统」重启即可

### 2.10 高可用部署

DataFlux Func 支持多份部署以满足高可用要求。

以阿里云为例，可使用「SLB + ECS x 2 + RDS + Redis」方式进行部署。

如果开发涉及到服务器端文件处理（如上传文件等）、额外安装Python包，
则需要额外配置NFS/NAS 作为文件共享存储。
并将共享挂载到ECS 的`{安装目录}/data/resources`目录。

```
                        +-------------+
                        |             |
                        |     SLB     |
                        |             |
                        +-------------+
                               |
                               |
                   +-----------+----------+
                   |                      |
                   v                      v
            +-------------+        +-------------+
            |             |        |             |
            |    ECS-1    |        |    ECS-2    |
            |             |        |             |
            +-------------+        +-------------+
                   |                      |
                   |                      |
       +-----------+----------+-----------+----------+
       |                      |                      |
       v                      v                      v
+-------------+        +-------------+        +-------------+
|             |        |             |        |             |
|     RDS     |        |    Redis    |        |   NFS/NAS   |
|             |        |             |        |  (optional) |
+-------------+        +-------------+        +-------------+
```

部署步骤：

1. 在ECS-1 全自动部署DataFlux Func，并配置连接外部RDS 和Redis
2. 在ECS-2 正常部署DataFlux Func，复制ECS-1的配置文件并覆盖ECS-2的配置文件，重启ECS-2的服务

*注意：如之前已经使用单机方式部署过DataFlux Func，在切换为高可用部署时，请参考上文「5.8 迁移数据库」进行迁移*

*注意：本方案为最简单的多份部署方案，由于ECS-1 与ECS-2 之间并不通讯，因此涉及到安装额外Python包、上传文件等处理时，需要使用共享文件存储*

## 3. 故障排查

由于系统本身具有一定复杂性，当遇到问题时，可以根据下文进行初步判断大概可能存在的问题点。

*注意：DataFlux Func 不支持集群部署的Redis，如集群部署的Redis 可能发生各种奇怪的问题*

### 3.1 安装部署时脚本中断

安装部署时，很多情况都有可能导致脚本中断，但一般都是由于不满足系统要求导致。

可能原因及解决方案：

|                      原因                     |                         解决方案                        |
|-----------------------------------------------|---------------------------------------------------------|
| 所用操作系统不支持Docker 及相关组件的安装运行 | 更换操作系统                                            |
| 主机具有多个网卡                              | 参考上文「README」中有关Docker Swarm 初始化的描述 |

在排除问题后，重新运行脚本即可

### 3.2 安装部署完成后无法启动

此问题一般是由于配置、防火墙、各种白名单配置不正确引起。

具体表现为：

1. 使用浏览器无法打开页面
2. 使用`docker ps -a`命令查看容器列表时，发现重启在不断重启
3. 在部署服务器本机使用`curl http://localhost:8088`返回`curl: (7) Failed to connect to localhost port 8088: Connection refused`错误
3. 日志文件中不断输出错误堆栈信息

可能原因及解决方案：

|                   原因                   |                           解决方案                           |
|------------------------------------------|--------------------------------------------------------------|
| 当前版本的系统确实存在BUG                | 更换其他版本，并联系驻云官方                                 |
| 手工修改过配置但配置存在错误             | 检查修改过的配置文件，检查如YAML语法、数据库链接信息是否正确 |
| 修改配置指定了外部服务器，但实际网络不通 | 检查防火墙、阿里云安全组配置、数据库链接白名单等配置         |

### 3.3 安装部署完成后启动成功但无法访问

此问题一般是由于网络问题引起。

具体表现为：

1. 在部署服务器本机使用`curl http://localhost:8088`正常返回`Found. Redirecting to /client-app`跳转信息
2. 在其他设备上使用`curl http://{服务器地址}:8088`无响应，或直接返回拒绝连接

可能原因及解决方案：

|                    原因                   |                 解决方案                 |
|-------------------------------------------|------------------------------------------|
| IP/域名解析等不正确                       | 检查并通过正确的地址访问                 |
| 服务器的防火墙、阿里云安全组配置不正确    | 修改配置，允许外部访问服务器的`8088`端口 |
| 额外增加了如Nginx做反向代理，但配置不正确 | 检查反向代理服务器的配置                 |

### 3.4 函数执行返回超时

函数执行超时可能有多种可能，需要根据不同情况进行辨别

#### 3.4.1 函数执行耗时过长导致工作进程被Kill

为了保护系统，DataFlux Func 对函数执行的最长时间有限制，不允许无限制运行下去。
在超过一定时间后，会直接Kill掉执行进程。

具体表现为：

1. 浏览器访问`/api/v1/al/auln-xxxxx`接口时，长时间卡在加载中状态
2. curl方式调用`GET|POST /api/v1/al/auln-xxxxx`接口返回状态码`599`，返回数据类似如下：

```json
{
    "detail": {
        "einfoTEXT": "raise SoftTimeLimitExceeded()\nbilliard.exceptions.SoftTimeLimitExceeded: SoftTimeLimitExceeded()",
        "id": "task-xxxxx"
    },
    "error": 599.31,
    "message": "Calling Function timeout.",
    "ok": false,
    "reason": "EFuncTimeout",
    "reqCost": 5020,
    "reqDump": {
        "method": "GET",
        "url": "/api/v1/al/auln-xxxxx"
    },
    "traceId": "TRACE-xxxxx"
}
```

其中，`reqCost`字段为此函数从开始执行到被Kill经过的时间（毫秒）

可能原因及解决方案：

|                               原因                              |                                         解决方案                                         |
|-----------------------------------------------------------------|------------------------------------------------------------------------------------------|
| 所执行的函数指定了`timeout`超时参数（秒），且函数运行超时       | 联系函数开发者排查错误，包括且不限于：<br>超时参数设置过短<br>函数内调用外部系统响应过慢 |
| 所执行的函数未指定`timeout`超时参数，但函数运行超过默认超时限制 | 同上                                                                                     |
| 使用浏览器访问时，耗时过长，浏览器主动断开连接                  | 联系函数开发者排查错误，无法提高响应时考虑其他异步方案                                   |

> 函数超时默认为`30秒`，最大设置为`3600秒`

#### 3.4.2 函数执行耗时过长导致API接口提前返回

为了保护系统，DataFlux Func 对使用HTTP 接口【同步】调用函数的最长响应时间有限制，不允许服务器无限制保持HTTP连接。
在超过一定时间后，API层面会放弃等待函数返回，直接响应HTTP 请求。

具体表现为：

1. 调用`GET|POST /api/v1/al/auln-xxxxx`接口返回状态码`599`，返回数据类似如下：

```json
{
    "detail": {
        "id": "task-xxxxx"
    },
    "error": 599.1,
    "message": "Waiting function result timeout, but task is still running. Use task ID to fetch result later.",
    "ok": false,
    "reason": "EAPITimeout",
    "reqCost": 3011,
    "reqDump": {
        "method": "GET",
        "url": "/api/v1/al/auln-xxxxx"
    },
    "traceId": "TRACE-xxxxx"
}
```

*注意：API接口超时仅表示HTTP 响应时间超时，此时函数可能依然在后台运行，并遵循函数超时处理逻辑*

可能原因及解决方案：

|                                  原因                                  |                                           解决方案                                          |
|------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|
| 所执行的函数指定了`api_timeout`API超时参数（秒），且函数运行超时       | 联系函数开发者排查错误，包括且不限于：<br>API超时参数设置过短<br>函数内调用外部系统响应过慢 |
| 所执行的函数未指定`api_timeout`API超时参数，但函数运行超过默认超时限制 | 同上                                                                                        |

> API超时默认为`10秒`，最大设置为`180秒`。同时，API超时不会长于函数超时

### 3.5 函数执行无响应

函数执行无响应可能有多种可能，需要根据不同情况进行辨别

具体表现为：

1. 浏览器访问接口时，长时间处于加载中状态
2. curl方式调用接口时，长时间没有任何响应

此时，需要在DataFlux Func 中写一个测试函数，并将其配置为「授权链接」，来帮助判断原因。

测试函数如下：

```python
@DFF.API('Test Func')
def test_func():
    return 'ok'
```

#### 3.5.1 测试函数有响应

可能原因及解决方案：

|              原因              |        解决方案        |
|--------------------------------|------------------------|
| 所调用函数确实需要运行很长时间 | 联系函数开发者排查问题 |

#### 3.5.2 测试函数无响应

可能原因及解决方案：

|        原因       |                  解决方案                  |
|-------------------|--------------------------------------------|
| 存在队列阻塞      | 前往「关于 - 获取系统报告 - 清空工作队列」 |
| Redis连接存在问题 | 重启系统，排查Redis连接配置是否正确        |
